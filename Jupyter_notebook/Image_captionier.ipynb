{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pickle\nimport numpy as np\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\n\nfrom tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical,plot_model\nfrom tensorflow.keras.layers import Input,Dense,LSTM,Embedding,Dropout,add","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-03T19:49:46.091558Z","iopub.execute_input":"2024-02-03T19:49:46.092132Z","iopub.status.idle":"2024-02-03T19:49:46.102492Z","shell.execute_reply.started":"2024-02-03T19:49:46.092092Z","shell.execute_reply":"2024-02-03T19:49:46.100828Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/flickr8k'\nWORKING_DIR = '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-02-03T16:33:04.844639Z","iopub.execute_input":"2024-02-03T16:33:04.845574Z","iopub.status.idle":"2024-02-03T16:33:04.849372Z","shell.execute_reply.started":"2024-02-03T16:33:04.845539Z","shell.execute_reply":"2024-02-03T16:33:04.848321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract Image Feature","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.models import Model\n\n# Path to the manually downloaded weights file\nweights_path = 'C:\\\\Users\\\\hp\\\\.keras\\\\models'\n\n# Load VGG16 model with the specified weights file\nmodel = VGG16(weights=None)\n\n# Restructure the model\nmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n\n# Summary\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T16:29:13.463155Z","iopub.execute_input":"2024-02-03T16:29:13.463609Z","iopub.status.idle":"2024-02-03T16:29:14.804254Z","shell.execute_reply.started":"2024-02-03T16:29:13.463581Z","shell.execute_reply":"2024-02-03T16:29:14.801730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features={}\ndirectory = os.path.join(BASE_DIR,'Images')\n\nfor img_name in tqdm(os.listdir(directory)):\n    img_path = directory + '/' + img_name\n    image = load_img(img_path , target_size = (224,224))\n    \n    image = img_to_array(image)\n    \n    image=image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n    image = preprocess_input(image)\n    feature = model.predict(image, verbose =0)\n    image_id = img_name.split('.')[0]\n    features[image_id] = feature\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T16:33:08.921937Z","iopub.execute_input":"2024-02-03T16:33:08.922367Z","iopub.status.idle":"2024-02-03T17:27:30.434790Z","shell.execute_reply.started":"2024-02-03T16:33:08.922336Z","shell.execute_reply":"2024-02-03T17:27:30.433335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle.dump(features,open(os.path.join(WORKING_DIR, 'features.pkl'),'wb'))","metadata":{"execution":{"iopub.status.busy":"2024-02-03T17:30:34.649432Z","iopub.execute_input":"2024-02-03T17:30:34.650034Z","iopub.status.idle":"2024-02-03T17:30:35.121833Z","shell.execute_reply.started":"2024-02-03T17:30:34.649987Z","shell.execute_reply":"2024-02-03T17:30:35.120230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(WORKING_DIR,'features.pkl'),'rb') as f:\n    features=pickle.load(f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the Captions Data","metadata":{}},{"cell_type":"code","source":"with open(os.path.join(BASE_DIR,'captions.txt'),'r') as f:\n    next(f)\n    captions_doc=f.read()","metadata":{"execution":{"iopub.status.busy":"2024-02-03T17:34:35.324110Z","iopub.execute_input":"2024-02-03T17:34:35.324710Z","iopub.status.idle":"2024-02-03T17:34:35.376703Z","shell.execute_reply.started":"2024-02-03T17:34:35.324674Z","shell.execute_reply":"2024-02-03T17:34:35.375344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = {}\n#process\nfor line  in tqdm(captions_doc.split('\\n')):\n    tokens=line.split(',')\n    if len(line)<2:\n        continue\n    image_id,caption = tokens[0],tokens[1:]\n    image_id = image_id.split('.')[0]\n    caption = \" \".join(caption)\n    if image_id not in mapping:\n        mapping[image_id] = []\n    mapping[image_id].append(caption)    \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-03T17:46:27.022248Z","iopub.execute_input":"2024-02-03T17:46:27.022773Z","iopub.status.idle":"2024-02-03T17:46:27.190430Z","shell.execute_reply.started":"2024-02-03T17:46:27.022702Z","shell.execute_reply":"2024-02-03T17:46:27.189278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(mapping)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T17:46:46.209003Z","iopub.execute_input":"2024-02-03T17:46:46.209451Z","iopub.status.idle":"2024-02-03T17:46:46.217788Z","shell.execute_reply.started":"2024-02-03T17:46:46.209417Z","shell.execute_reply":"2024-02-03T17:46:46.216199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"def clean (mapping):\n    for key,captions in mapping.items():\n        for i in range(len(captions)):\n            caption=captions[i]\n            #convert to lowercase\n            caption=caption.lower()\n            #delete digits , special characters etc\n            caption=caption.replace('[^A-Za-z]','')\n            #delete additional spaces\n            caption=caption.replace('\\s+', ' ')\n            #add start and end tags\n            caption = '<start>' + \" \".join([word for word in caption.split() if len(word)>1]) + '<end>'\n            captions[i]=caption\n            \n            \n            \n            ","metadata":{"execution":{"iopub.status.busy":"2024-02-03T18:20:14.533864Z","iopub.execute_input":"2024-02-03T18:20:14.534340Z","iopub.status.idle":"2024-02-03T18:20:14.542637Z","shell.execute_reply.started":"2024-02-03T18:20:14.534305Z","shell.execute_reply":"2024-02-03T18:20:14.541512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping['1000268201_693b08cb0e']","metadata":{"execution":{"iopub.status.busy":"2024-02-04T01:14:04.256113Z","iopub.execute_input":"2024-02-04T01:14:04.258485Z","iopub.status.idle":"2024-02-04T01:14:04.271956Z","shell.execute_reply.started":"2024-02-04T01:14:04.258400Z","shell.execute_reply":"2024-02-04T01:14:04.270243Z"},"trusted":true},"execution_count":149,"outputs":[{"execution_count":149,"output_type":"execute_result","data":{"text/plain":"['A child in a pink dress is climbing up a set of stairs in an entry way .',\n 'A girl going into a wooden building .',\n 'A little girl climbing into a wooden playhouse .',\n 'A little girl climbing the stairs to her playhouse .',\n 'A little girl in a pink dress going into a wooden cabin .']"},"metadata":{}}]},{"cell_type":"code","source":"clean(mapping)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping['1000268201_693b08cb0e']","metadata":{"execution":{"iopub.status.busy":"2024-02-04T01:14:15.311372Z","iopub.execute_input":"2024-02-04T01:14:15.311812Z","iopub.status.idle":"2024-02-04T01:14:15.323666Z","shell.execute_reply.started":"2024-02-04T01:14:15.311749Z","shell.execute_reply":"2024-02-04T01:14:15.321631Z"},"trusted":true},"execution_count":150,"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"['A child in a pink dress is climbing up a set of stairs in an entry way .',\n 'A girl going into a wooden building .',\n 'A little girl climbing into a wooden playhouse .',\n 'A little girl climbing the stairs to her playhouse .',\n 'A little girl in a pink dress going into a wooden cabin .']"},"metadata":{}}]},{"cell_type":"code","source":"all_captions = []\nfor key in mapping:\n    for caption in mapping[key]:\n        all_captions.append(caption)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T18:35:02.743377Z","iopub.execute_input":"2024-02-03T18:35:02.744164Z","iopub.status.idle":"2024-02-03T18:35:02.782859Z","shell.execute_reply.started":"2024-02-03T18:35:02.744118Z","shell.execute_reply":"2024-02-03T18:35:02.781238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_captions)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T18:35:08.258088Z","iopub.execute_input":"2024-02-03T18:35:08.258524Z","iopub.status.idle":"2024-02-03T18:35:08.266494Z","shell.execute_reply.started":"2024-02-03T18:35:08.258489Z","shell.execute_reply":"2024-02-03T18:35:08.265182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_captions[:10]","metadata":{"execution":{"iopub.status.busy":"2024-02-03T18:35:50.751973Z","iopub.execute_input":"2024-02-03T18:35:50.752913Z","iopub.status.idle":"2024-02-03T18:35:50.761397Z","shell.execute_reply.started":"2024-02-03T18:35:50.752867Z","shell.execute_reply":"2024-02-03T18:35:50.760223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(all_captions)\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2024-02-03T18:39:12.410872Z","iopub.execute_input":"2024-02-03T18:39:12.411351Z","iopub.status.idle":"2024-02-03T18:39:13.292987Z","shell.execute_reply.started":"2024-02-03T18:39:12.411317Z","shell.execute_reply":"2024-02-03T18:39:13.291821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-02-03T18:39:18.758424Z","iopub.execute_input":"2024-02-03T18:39:18.758873Z","iopub.status.idle":"2024-02-03T18:39:18.766404Z","shell.execute_reply.started":"2024-02-03T18:39:18.758839Z","shell.execute_reply":"2024-02-03T18:39:18.765228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = max(len(caption.split()) for caption in all_captions)\nmax_length","metadata":{"execution":{"iopub.status.busy":"2024-02-03T19:29:30.694358Z","iopub.execute_input":"2024-02-03T19:29:30.694838Z","iopub.status.idle":"2024-02-03T19:29:30.744968Z","shell.execute_reply.started":"2024-02-03T19:29:30.694796Z","shell.execute_reply":"2024-02-03T19:29:30.744084Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"image_ids=list(mapping.keys())\nsplit = int(len(image_ids)*0.90)\ntrain = image_ids[:split]\ntest=image_ids[split:]","metadata":{"execution":{"iopub.status.busy":"2024-02-03T19:40:58.902782Z","iopub.execute_input":"2024-02-03T19:40:58.903258Z","iopub.status.idle":"2024-02-03T19:40:58.911409Z","shell.execute_reply.started":"2024-02-03T19:40:58.903225Z","shell.execute_reply":"2024-02-03T19:40:58.910068Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n    n = 0\n    X1, X2, y = None, None, []\n    \n    while True:\n        for key in data_keys:\n            n += 1\n            captions = mapping[key]\n\n            for caption in captions:\n                seq = tokenizer.texts_to_sequences([caption])[0]\n\n                for i in range(1, len(seq)):\n                    in_seq, out_seq = seq[:i], seq[i]\n                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n\n                    if X1 is None:\n                        X1 = np.array([features[key][0]])\n                    else:\n                        X1 = np.concatenate([X1, np.array([features[key][0]])], axis=0)\n\n                    in_seq = np.expand_dims(in_seq, axis=0)\n\n                    if X2 is not None and X2.shape[1] == in_seq.shape[1]:\n                        X2 = np.vstack([X2, in_seq])\n                    else:\n                        X2 = in_seq\n\n                    y.append(out_seq)\n\n            if n == batch_size:\n                yield [X1, X2], np.array(y)\n                X1, X2, y = None, None, []\n                n = 0\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T20:53:24.617112Z","iopub.execute_input":"2024-02-03T20:53:24.617526Z","iopub.status.idle":"2024-02-03T20:53:24.630914Z","shell.execute_reply.started":"2024-02-03T20:53:24.617495Z","shell.execute_reply":"2024-02-03T20:53:24.629399Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"## Model Creation","metadata":{}},{"cell_type":"code","source":"#save\nmodel.save(WORKING_DIR+'/best_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Captions for the Image","metadata":{}},{"cell_type":"code","source":"def idx_to_word(integer,tokenizer):\n    for word,index in tokenizer.word_index.items():\n        if index == integer:\n            return word\n    return none    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def index_to_word(index, tokenizer):\n    for word, idx in tokenizer.word_index.items():\n        if idx == index:\n            return word","metadata":{"execution":{"iopub.status.busy":"2024-02-03T21:37:14.728788Z","iopub.execute_input":"2024-02-03T21:37:14.729705Z","iopub.status.idle":"2024-02-03T21:37:14.735805Z","shell.execute_reply.started":"2024-02-03T21:37:14.729652Z","shell.execute_reply":"2024-02-03T21:37:14.734478Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"def predict_caption(model,image,tokenizer,max_length):\n    in_text='<start>'\n    for i in range(max_length):\n        sequence=tokenizer.texts_to_sequences([in_text])[0]\n        sequence=pad_sequences([sequence],max_length)\n        yhat=model.predict([image,sequence],verbose=0)\n        yhat=np.argmax(yhat)\n        word = index_to_word(yhat, tokenizer)\n        if word is None:\n            break\n        in_text += \" \" + word\n        if word == '<end>':\n            break\n    return in_text       \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-03T21:38:03.249509Z","iopub.execute_input":"2024-02-03T21:38:03.250256Z","iopub.status.idle":"2024-02-03T21:38:03.259381Z","shell.execute_reply.started":"2024-02-03T21:38:03.250218Z","shell.execute_reply":"2024-02-03T21:38:03.257940Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\nactual,predicted = list(),list()\n\nfor key in tqdm(test):\n    captions=mapping[key]\n    y_pred=predict_caption(model,features[key],tokenizer,max_length)\n    actual_captions=[caption.split() for caption in captions]\n    y_pred=y_pred.split()\n    actual.append(actual_captions)\n    predicted.append(y_pred)\n    \nprint(\"BLEU-1: %f\" % corpus_bleu(actual,predicted,weights=(1.0,0,0,0)))\nprint(\"BLEU-2: %f\" % corpus_bleu(actual,predicted,weights=(0.5,0.5,0,0)))","metadata":{"execution":{"iopub.status.busy":"2024-02-04T02:21:11.628921Z","iopub.execute_input":"2024-02-04T02:21:11.631288Z","iopub.status.idle":"2024-02-04T03:12:23.070726Z","shell.execute_reply.started":"2024-02-04T02:21:11.631213Z","shell.execute_reply":"2024-02-04T03:12:23.069310Z"},"trusted":true},"execution_count":152,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/810 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0db23c42b59543dba2f48324da48b70a"}},"metadata":{}},{"name":"stdout","text":"BLEU-1: 0.191293\nBLEU-2: 0.099497\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\ndef generate_caption():\n    image_name=\"1007320043_627395c3d8.jpg\"\n    image_id=image.name.split('.')[0]\n    image_path=os.path.join(BASE_DIR,\"Images\",image_name)\n    image=Image.open(img_path)\n    captions=mapping[image_id]\n    print(\"-------Actual-----------\")\n    for caption in caption:\n        print(caption)\n    y_pred = predict_caption(model,features[image_id],tokenizer,max_length)\n    print(\"-------------Predicted-------------\")\n    print(y_pred)\n    plt.inshow(image)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T21:45:15.802069Z","iopub.execute_input":"2024-02-03T21:45:15.802987Z","iopub.status.idle":"2024-02-03T21:45:15.810493Z","shell.execute_reply.started":"2024-02-03T21:45:15.802949Z","shell.execute_reply":"2024-02-03T21:45:15.809440Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"generate_caption(\"1022454332_6af2c1449a.jpg\")","metadata":{"execution":{"iopub.status.busy":"2024-02-03T21:52:47.152634Z","iopub.status.idle":"2024-02-03T21:52:47.153094Z","shell.execute_reply.started":"2024-02-03T21:52:47.152881Z","shell.execute_reply":"2024-02-03T21:52:47.152900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}